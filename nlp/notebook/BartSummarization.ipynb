{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec1c36-7ed2-4cc5-896b-83778219ba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install  -r  requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6dbcf9-7def-4a9b-a69a-b8bca937e907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install  llama-cpp-python --no-cache-dir\n",
    "#!pip install -q llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80df9b16-81dd-4436-af6e-1a4cd98a260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "import pandas as pd\n",
    "import json\n",
    "from llama_index.llms import LlamaCPP\n",
    "from llama_index.llms.llama_utils import messages_to_prompt, completion_to_prompt\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from llama_index import LangchainEmbedding, ServiceContext, Document\n",
    "from llama_index import set_global_service_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afd6f58f-dbaf-4b89-b164-8f359adf94cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Constants and global variables\n",
    "s3_input_file_path ='s3://abb8-ml-model/dailydownload/mailContents.json'\n",
    "s3_output_file_path ='s3://abb8-ml-model/dailydownload/insights.json'\n",
    "s3_prompt_questions_path='./data/questions.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a39d176-3b96-4c71-b08e-f0b16ffb36e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   thread_id  mail_subject                                          mail_body   \n",
      "0       1001  utility_bill   Rob, We hope that you’re enjoying your electr...  \\\n",
      "\n",
      "  insight_dates summary  \n",
      "0                        \n",
      "                                            question\n",
      "0  Can you please convert the given text material...\n"
     ]
    }
   ],
   "source": [
    "    #print(df)\n",
    "    #print(df[\"mail_body\"][1])\n",
    "docs = pd.read_json(s3_input_file_path)\n",
    "docs.insert(3,\"insight_dates\",\"\")\n",
    "docs.insert(4,\"summary\",\"\")\n",
    "questions=pd.read_json(s3_prompt_questions_path)\n",
    "print(docs.head(1))\n",
    "print(questions.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56f7989d-3bef-44be-8fbb-95d036db037c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id_='6f7f56cc-9a36-4428-9852-4cd61fa77a53', embedding=None, metadata={'file_path': 'data/1001.txt', 'creation_date': '2023-11-09', 'last_modified_date': '2023-11-09', 'last_accessed_date': '2023-11-09'}, excluded_embed_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, hash='7b4c211a6382104957e08c26acf5d326457a28d03a38dbd3801bb201b35b00b4', text='Hello Natasha,Just a friendly reminder about your upcoming appointment with DR. Janet Baker DDS. Please confirm your appointment by clicking the button below.____________________Your appointment is: Tuesday, December 16 2023  3:30 PM', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='19a8762b-c1b9-41de-a0ef-c5657e2340c3', embedding=None, metadata={'file_path': 'data/1002.txt', 'creation_date': '2023-11-09', 'last_modified_date': '2023-11-09', 'last_accessed_date': '2023-11-09'}, excluded_embed_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, hash='b05f1c2527f6b7b971e0c488c9dab149df44c7944732621d97d8b0906d000f1a', text='PARENT-TEACHER CONFERENCE REMINDER -springfield elementary school  Date: ___11/25/2023_______________________ To the parent(s) of __Isabella__________________________________,Just a reminder that we have a parent-teacher conference scheduled for ________Robert  Connor Family______________on _11/25/2023_____________________ at _____10:30______________ a.m./p.m.in room number __225__________. Our conference will run approximately ___30____ minutes long.Please contact the school t (____240___)__5891234___________________ if you are unable to make this scheduled appointment. I am looking forward to meeting with you and discussing your child’s progress.Your child’s teacher, ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='e6825e59-7fb2-4f76-9338-444a10fbadec', embedding=None, metadata={'file_path': 'data/mailcontents.txt', 'creation_date': '2023-11-07', 'last_modified_date': '2023-11-07', 'last_accessed_date': '2023-11-07'}, excluded_embed_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, hash='c4f09f36eff5c77a2c2263b7eeb36a15624f2f22b1a42672857c835f055455fd', text='Hi Rob, We hope that you’re enjoying your electricity utility service. \\n    At  Pepco we take pride in making sure that all of our customers enjoy what we provide them. \\n    I did want to quickly mention that we haven’t received payment from you just yet.\\n    No worries, it isn’t due until 10/30/2023 (one week from today).You can pay by mailing us a check at Pepco Baltimore or online \\n    If you have any questions don’t hesitate to reply to this email or give us a call at 1-888-456-7894\\n    \\n\\n\\nPARENT-TEACHER CONFERENCE REMINDER -springfield elementary school\\nDate: ___11/25/2023_______________________\\nTo the parent(s) of __Isabella__________________________________,\\nJust a reminder that we have a parent-teacher conference scheduled for\\n________Robert  Connor Family______________on _11/25/2023_____________________ at _____10:30______________ a.m./p.m.\\nin room number __225__________. Our conference will run approximately ___30____ minutes long.\\nPlease contact the school o\\x1fce at (____240___)__5891234___________________ if you are unable to\\nmake this scheduled appointment.\\nI am looking forward to meeting with you and discussing your child’s progress.\\nYour child’s teacher,\\n\\nHello Natasha,\\n\\nJust a friendly reminder about your upcoming appointment with DR. Janet Baker DDS. Please confirm your appointment by clicking the button below.\\n\\n____________________\\n\\nYour appointment is: Tuesday, December 16 2023  3:30 PM', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='ff0e30ac-485d-48aa-aaf9-43baac292f18', embedding=None, metadata={'file_path': 'data/questions.json', 'creation_date': '2023-11-08', 'last_modified_date': '2023-11-08', 'last_accessed_date': '2023-11-08'}, excluded_embed_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, hash='61085fb0fe4f963a4373f62c451bbace5bfc5a778928e13cc833d3eb1b523639', text='[{\"question\": \"Can you please convert the given text material into JSON format with the appointment dates and context included?\"},\\n {\"question\": \"write a concise summary of the documents in 2 bullet points based on the given text material in JSON format?\"}\\n]', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(\"./data/\").load_data()\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7da58db8-5e93-4e2a-8a1d-e4e5f8dba5bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_insights():    \n",
    "    #documents = []\n",
    "    for index,row in docs.iterrows():\n",
    "        documents = []\n",
    "        thread_id=row[\"thread_id\"]\n",
    "        thread_text=row[\"mail_body\"]\n",
    "        thread_subject=row[\"mail_subject\"]\n",
    "        #document = Document(text=thread_text,id_=thread_id,metadata={\"subject\":thread_subject})\n",
    "        documents.append(\n",
    "            Document(text=thread_text,id_=thread_id,metadata={\"subject\":thread_subject})\n",
    "        )\n",
    "        service_context=get_service_context();\n",
    "        index=VectorStoreIndex.from_documents(documents,service_context=service_context)\n",
    "        query_engine = index.as_query_engine()\n",
    "        for index,row in questions.iterrows():\n",
    "            response = query_engine.query(row[\"question\"])\n",
    "            print('creating summary for ' + thread_subject)\n",
    "            print(response)\n",
    "            if index == 0:\n",
    "                docs.at[index,'insight_dates']=response\n",
    "            else:\n",
    "                docs.at[index,'summary']=response\n",
    "        #index.delete(thread_id)\n",
    "    print(docs.head(1))    \n",
    "    docs.to_json('s3://abb8-ml-model/dailydownload/insights.json',orient='records')        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e99d7c-648a-4940-b70e-101cefd5435a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs['json'] = docs.apply(lambda x: x.to_json(), axis=1)\n",
    "for index,row in docs.iterrows():\n",
    "    f = open('./data/'+str(row[\"thread_id\"])+'.txt', 'w')\n",
    "    f.write(row[\"mail_body\"])\n",
    "    f.close()\n",
    "    documents = SimpleDirectoryReader(input_files=['./data/'+str(row[\"thread_id\"])+'.txt']).load_data()\n",
    "    #print(documents)\n",
    "    print('index' + str(index))\n",
    "    service_context=get_service_context();\n",
    "    llamind=VectorStoreIndex.from_documents(documents,service_context=service_context)   \n",
    "    \n",
    "    query_engine = llamind.as_query_engine()\n",
    "    print('creating summary for ' + str(row[\"thread_id\"]))\n",
    "    for index,row in questions.iterrows():        \n",
    "        print(row[\"question\"])\n",
    "        response = query_engine.query(row[\"question\"])        \n",
    "        print(response)\n",
    "        if index == 0:\n",
    "            docs.at[index,'insight_dates']=response\n",
    "        else:\n",
    "            docs.at[index,'summary']=response\n",
    "print(docs.head(1))    \n",
    "docs.to_json('s3://abb8-ml-model/dailydownload/insights.json',orient='records')              \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c18197c5-4c4f-49ed-a7fc-06b466e52221",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    {\"thread_id\":1001,\"mail_subject\":\"utility_bill...\n",
      "1    {\"thread_id\":1002,\"mail_subject\":\"utility_bill...\n",
      "2    {\"thread_id\":1001,\"mail_subject\":\"utility_bill...\n",
      "Name: json, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(docs['json'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002bf1fd-b8ea-43a4-9a60-4a20ff4d3f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a66ff7-ff25-4f3e-b68a-8e9219b1ad25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c9c032f-1913-4455-8d23-69ad800e5dad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_service_context():    \n",
    "    llm = LlamaCPP(\n",
    "        # You can pass in the URL to a GGML model to download it automatically\n",
    "        model_url=None,\n",
    "        # optionally, you can set the path to a pre-downloaded model instead of model_url\n",
    "        model_path='./models/zephyr-7b-alpha.Q5_K_M.gguf',\n",
    "        temperature=0.1,\n",
    "        max_new_tokens=256,\n",
    "        # llama2 has a context window of 4096 tokens, but we set it lower to allow for some wiggle room\n",
    "        context_window=3900,\n",
    "        # kwargs to pass to __call__()\n",
    "        generate_kwargs={},\n",
    "        # kwargs to pass to __init__()\n",
    "        # set to at least 1 to use GPU\n",
    "        model_kwargs={\"n_gpu_layers\": -1},\n",
    "        # transform inputs into Llama2 format\n",
    "        messages_to_prompt=messages_to_prompt,\n",
    "        completion_to_prompt=completion_to_prompt,\n",
    "        verbose=True,\n",
    "    )\n",
    "    embed_model = LangchainEmbedding(\n",
    "      HuggingFaceEmbeddings(model_name=\"thenlper/gte-large\")\n",
    "    )\n",
    "    service_context = ServiceContext.from_defaults(\n",
    "        chunk_size=256,\n",
    "        llm=llm,\n",
    "        embed_model=embed_model\n",
    "    )\n",
    "    return service_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e537df3-c2ca-443d-8ce4-31fa52c424b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e524001-1ed0-42e6-9ce0-e19a7bf5a906",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create and set service context just once never include this in any loops\n",
    "service_context=get_service_context();\n",
    "#set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53c48d10-ff26-44a6-ac59-9b290d45817f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index=VectorStoreIndex.from_documents(documents,service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff6a184-71f4-4fab-84f7-7c8fd7b126f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(docs.head(1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2477b141-18fb-4168-acc4-f05f1a74cfe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index,row in docs.iterrows():\n",
    "        documents = []\n",
    "        thread_id=row[\"thread_id\"]\n",
    "        thread_text=row[\"mail_body\"]\n",
    "        thread_subject=row[\"mail_subject\"]\n",
    "        #document = Document(text=thread_text,id_=thread_id,metadata={\"subject\":thread_subject})\n",
    "        documents.append(\n",
    "            Document(text=thread_text,id_=thread_id,metadata={\"subject\":thread_subject})\n",
    "        )\n",
    "        print(documents)\n",
    "        service_context=get_service_context();\n",
    "        index=VectorStoreIndex.from_documents(documents,service_context=service_context)\n",
    "        print(index.ref_doc_info)\n",
    "        query_engine = index.as_query_engine()\n",
    "        for index,row in questions.iterrows():\n",
    "            print('question is:' +row[\"question\"])\n",
    "            response = query_engine.query(row[\"question\"])\n",
    "            print('creating summary for ' + thread_subject)\n",
    "            print(response)\n",
    "            if index == 0:\n",
    "                docs.at[index,'insight_dates']=response\n",
    "            else:\n",
    "                docs.at[index,'summary']=response\n",
    "        #index.delete(thread_id)\n",
    "print(docs.head(1))    \n",
    "docs.to_json('s3://abb8-ml-model/dailydownload/insights.json',orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeb1da6-a6a8-4d7e-82f5-e8fc438558b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_insights()\n",
    "#print (documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a5cc9fe-d61d-486b-8e26-36334fca06f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9244c670-b0f6-43a7-bd33-649a6935de2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "{\n",
      "  \"appointment\": {\n",
      "    \"date\": \"Tuesday, December 16 2023\",\n",
      "    \"time\": \"3:30 PM\"\n",
      "  },\n",
      "  \"context\": \"Hello Natasha,\\nJust a friendly reminder about your upcoming appointment with DR. Janet Baker DDS.\\nPlease confirm your appointment by clicking the button below.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Can you please provide the dates and context as json  in the given text material?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45447acd-852b-4822-a01b-62e54abfdc9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from llama_index import set_global_service_context\n",
    "#set_global_service_context(service_context)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b15cfd1-5eac-4c26-a3e4-e9d7b89b7858",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82d2e6e9-9d2d-418d-a2f1-2184aef04695\n",
      "{'6f7f56cc-9a36-4428-9852-4cd61fa77a53': RefDocInfo(node_ids=['cb424b3e-fa45-47c7-bcc0-c03d9e0a94e2'], metadata={'file_path': 'data/1001.txt', 'creation_date': '2023-11-09', 'last_modified_date': '2023-11-09', 'last_accessed_date': '2023-11-09'}), '19a8762b-c1b9-41de-a0ef-c5657e2340c3': RefDocInfo(node_ids=['46e23126-054b-495c-932f-acd0c14190a4'], metadata={'file_path': 'data/1002.txt', 'creation_date': '2023-11-09', 'last_modified_date': '2023-11-09', 'last_accessed_date': '2023-11-09'}), 'e6825e59-7fb2-4f76-9338-444a10fbadec': RefDocInfo(node_ids=['37694768-ebbe-4871-8547-6d5e036dc7a7', '12b9c48f-78dc-4cba-ae97-22532e644195'], metadata={'file_path': 'data/mailcontents.txt', 'creation_date': '2023-11-07', 'last_modified_date': '2023-11-07', 'last_accessed_date': '2023-11-07'}), 'ff0e30ac-485d-48aa-aaf9-43baac292f18': RefDocInfo(node_ids=['f3720a3f-bc55-4154-b64e-ef3e6cbd7b71'], metadata={'file_path': 'data/questions.json', 'creation_date': '2023-11-08', 'last_modified_date': '2023-11-08', 'last_accessed_date': '2023-11-08'})}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(index.index_id)\n",
    "print(index.ref_doc_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a252d7f-6e58-407a-87f7-7a91e4f2b9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001d",
      "SYS>>\n",
      "\n",
      "Parent-teacher conference reminder for Isabella's family scheduled for Nov. 25th at 10:30 a.m./p.m. in room 225, lasting approximately 30 minutes. Contact school if unable to attend.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"write a concise summary of the document id 1001 with 10 words based on the given text material.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c091e097-e626-40b8-8e57-e14bc6fbbc79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#index.delete('7a91dfe9-5b66-4cdb-b5f4-dc54671e7c8a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d11488d-1b2c-4148-91b0-8b3ec54fa082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is the deadline to pay utility bill ?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f0f52c-3014-4e13-bbd9-e6d435a1cc9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a520c1-d8c2-4e29-947d-b65b9546512a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = query_engine.query(\"Can you please convert the given text material into JSON format with the appointment dates and context included? \")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f0ee399-0f5b-4280-82b7-3d56e429b0dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from ./models/zephyr-7b-alpha.Q5_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q5_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:            blk.0.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:            blk.0.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:              blk.0.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:         blk.0.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:              blk.0.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:              blk.0.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:            blk.1.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:            blk.1.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:         blk.1.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:              blk.1.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:              blk.1.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:           blk.10.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:           blk.10.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:             blk.10.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:             blk.10.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:        blk.10.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:             blk.10.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:             blk.10.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:           blk.11.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:           blk.11.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:             blk.11.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:             blk.11.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:        blk.11.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:             blk.11.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:             blk.11.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:           blk.12.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:           blk.12.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:             blk.12.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:             blk.12.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:        blk.12.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:             blk.12.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:             blk.12.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:           blk.13.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:           blk.13.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:             blk.13.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:             blk.13.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:        blk.13.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:             blk.13.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:             blk.13.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:           blk.14.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:           blk.14.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:             blk.14.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:             blk.14.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:        blk.14.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:             blk.14.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:             blk.14.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:           blk.15.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:           blk.15.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:             blk.15.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:             blk.15.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:        blk.15.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:             blk.15.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:             blk.15.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:           blk.16.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:           blk.16.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:             blk.16.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:             blk.16.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:        blk.16.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:             blk.16.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:             blk.16.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:           blk.17.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:           blk.17.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:             blk.17.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:             blk.17.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:        blk.17.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:             blk.17.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:             blk.17.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:           blk.18.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:           blk.18.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:             blk.18.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:             blk.18.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:        blk.18.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:             blk.18.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:             blk.18.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:           blk.19.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:           blk.19.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:             blk.19.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:             blk.19.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:        blk.19.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:             blk.19.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:             blk.19.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:            blk.2.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:            blk.2.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:              blk.2.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:              blk.2.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:         blk.2.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:              blk.2.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:              blk.2.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:           blk.20.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:           blk.20.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:             blk.20.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:             blk.20.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:        blk.20.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:             blk.20.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:             blk.20.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:           blk.21.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:           blk.21.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:             blk.21.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:             blk.21.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:        blk.21.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:             blk.21.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:             blk.21.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:             blk.22.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:        blk.22.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:             blk.22.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:             blk.22.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:            blk.3.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:            blk.3.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:              blk.3.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:              blk.3.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:         blk.3.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:              blk.3.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:              blk.3.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:            blk.4.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:            blk.4.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:              blk.4.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:              blk.4.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:         blk.4.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:              blk.4.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:              blk.4.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:            blk.5.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:            blk.5.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:              blk.5.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:              blk.5.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:         blk.5.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:              blk.5.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:              blk.5.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:            blk.6.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:            blk.6.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:              blk.6.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:              blk.6.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:         blk.6.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:              blk.6.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:              blk.6.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:            blk.7.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:            blk.7.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:              blk.7.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:              blk.7.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:         blk.7.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:              blk.7.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:              blk.7.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:            blk.8.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:            blk.8.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:              blk.8.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:              blk.8.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:         blk.8.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:              blk.8.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:              blk.8.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:            blk.9.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:            blk.9.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:              blk.9.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:              blk.9.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:         blk.9.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:              blk.9.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:              blk.9.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:                    output.weight q6_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:           blk.22.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:           blk.22.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:             blk.22.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:           blk.23.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:           blk.23.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:             blk.23.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:             blk.23.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:        blk.23.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:             blk.23.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:             blk.23.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:           blk.24.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:           blk.24.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:             blk.24.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:             blk.24.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:        blk.24.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:             blk.24.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:             blk.24.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:           blk.25.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:           blk.25.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:             blk.25.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:             blk.25.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:        blk.25.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:             blk.25.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:             blk.25.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:           blk.26.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:           blk.26.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:             blk.26.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:             blk.26.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:        blk.26.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:             blk.26.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:             blk.26.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:           blk.27.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:           blk.27.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:             blk.27.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:             blk.27.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:        blk.27.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:             blk.27.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:             blk.27.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:           blk.28.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:           blk.28.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:             blk.28.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:             blk.28.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:        blk.28.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:             blk.28.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:             blk.28.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:           blk.29.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:           blk.29.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:             blk.29.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:             blk.29.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:        blk.29.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:             blk.29.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:             blk.29.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:           blk.30.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:           blk.30.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:             blk.30.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:             blk.30.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:        blk.30.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:             blk.30.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:             blk.30.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:           blk.31.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:           blk.31.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:             blk.31.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:             blk.31.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:        blk.31.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:             blk.31.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:             blk.31.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str     \n",
      "llama_model_loader: - kv   1:                               general.name str     \n",
      "llama_model_loader: - kv   2:                       llama.context_length u32     \n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32     \n",
      "llama_model_loader: - kv   4:                          llama.block_count u32     \n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32     \n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32     \n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32     \n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32     \n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32     \n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32     \n",
      "llama_model_loader: - kv  11:                          general.file_type u32     \n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str     \n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr     \n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr     \n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr     \n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32     \n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32     \n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32     \n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32     \n",
      "llama_model_loader: - kv  20:               general.quantization_version u32     \n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q5_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = mostly Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.78 GiB (5.67 BPW) \n",
      "llm_load_print_meta: general.name   = huggingfaceh4_zephyr-7b-alpha\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token = 2 '</s>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MB\n",
      "llm_load_tensors: mem required  = 4893.10 MB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 3900\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: kv self size  =  487.50 MB\n",
      "llama_build_graph: non-view tensors processed: 740/740\n",
      "llama_new_context_with_model: compute buffer total size = 282.00 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n",
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "llama_print_timings:        load time =   79044.16 ms\n",
      "llama_print_timings:      sample time =      25.45 ms /    52 runs   (    0.49 ms per token,  2043.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =   79043.79 ms /   320 tokens (  247.01 ms per token,     4.05 tokens per second)\n",
      "llama_print_timings:        eval time =   17598.64 ms /    51 runs   (  345.07 ms per token,     2.90 tokens per second)\n",
      "llama_print_timings:       total time =   96809.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  \"person\": \"Robert Connor Family\",\n",
      "  \"meeting_date\": \"11/25/2023\",\n",
      "  \"place\": \"room number __225__\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"person\": \"Natasha\",\n",
      "  \"meeting_date\": \"Tuesday, December 16 2023\",\n",
      "  \"place\": null\n",
      "}\n",
      "   thread_id        mail_subject   \n",
      "0       1001        utility_bill  \\\n",
      "1       1002  utility_bill march   \n",
      "\n",
      "                                           mail_body insight_dates   \n",
      "0   Rob, We hope that you’re enjoying your electr...                \\\n",
      "1  PARENT-TEACHER CONFERENCE REMINDER -springfiel...                 \n",
      "\n",
      "                                             summary  \n",
      "0                                                     \n",
      "1  \\n{\\n  \"person\": \"Robert Connor Family\",\\n  \"m...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   79044.16 ms\n",
      "llama_print_timings:      sample time =      21.57 ms /    43 runs   (    0.50 ms per token,  1993.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =   27722.73 ms /   113 tokens (  245.33 ms per token,     4.08 tokens per second)\n",
      "llama_print_timings:        eval time =   14803.14 ms /    42 runs   (  352.46 ms per token,     2.84 tokens per second)\n",
      "llama_print_timings:       total time =   42665.19 ms\n"
     ]
    }
   ],
   "source": [
    "service_context=get_service_context();\n",
    "for index,row in docs.iterrows():\n",
    "    if index >= 1:\n",
    "        documents = []\n",
    "        thread_id=row[\"thread_id\"]\n",
    "        thread_text=row[\"mail_body\"]\n",
    "        thread_subject=row[\"mail_subject\"]\n",
    "        #document = Document(text=thread_text,id_=thread_id,metadata={\"subject\":thread_subject})\n",
    "        documents.append(\n",
    "            Document(text=thread_text,id_=thread_id,metadata={\"subject\":thread_subject})\n",
    "        )\n",
    "        #print(documents)        \n",
    "        llamaindex=VectorStoreIndex.from_documents(documents,service_context=service_context)\n",
    "        ##print(index.ref_doc_info)\n",
    "        query_engine = llamaindex.as_query_engine(response_mode=\"compact\")\n",
    "        response = query_engine.query('''Give me info on the following points in JSON format-\n",
    "                              person\n",
    "                              meeting_date\n",
    "                              place\n",
    "                              ''')\n",
    "        docs.at[index,'summary']=response\n",
    "        print(response)\n",
    "        #index.delete(thread_id)\n",
    "print(docs.head(2))    \n",
    "docs.to_json('s3://abb8-ml-model/dailydownload/insights.json',orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77355db-f91f-4423-9e60-75ec52f5e782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from datetime import datetime, timezone\n",
    "service_context=get_service_context();\n",
    "index=VectorStoreIndex.from_documents(documents,service_context=service_context)\n",
    "class insightInfo(BaseModel):\n",
    "    person: List[str]\n",
    "    meeting_date: str\n",
    "    place:str\n",
    "\n",
    "query_engine = index.as_query_engine(response_mode=\"compact\")\n",
    "response = query_engine.query('''Give me info on the following points in JSON format-\n",
    "                              person\n",
    "                              meeting_date\n",
    "                              place\n",
    "                              ''')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8fc019-5019-4080-a61b-d0b186499722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"is there an upcoming doctor appointment for Natasha?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac072bc-6e64-4a73-a276-c3c0bed7f3f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"is there an upcoming  parent teacher confernce for rob?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2121fc0-b8af-49a6-b66e-9785535997fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"list the upcoming tasks like doctor appointment, utility bill?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8f6b25-3ab6-4a03-ac60-c33a226de69a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5211861a-f601-4644-9ac4-040b065c0d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4d1d85-b926-4c6a-addc-6f47a238c199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51308cc-2a5d-4fa0-9d8c-a83a64cb535d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import S3DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affe670a-69d8-4a3b-b700-7aa285f35399",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('./data/')\n",
    "#bucket='abb8-ml-model',prefix='dailydownload'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4d25c0-857d-4e0c-af8a-268d49607f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -- quite unstructured\n",
    "documents =loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9a92b6-c054-4ebb-8bb4-fc05c3540e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fffbb2-d43a-4b48-a621-f0572f632a92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "persist_directory = 'vectordb'\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=25)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f65606c-cff3-49ce-9367-a5ddda37e4cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings, SentenceTransformerEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"thenlper/gte-large\")\n",
    "# HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e8d07-9e22-4cea-803e-8e4e8f7ed108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(documents=texts,                                 \n",
    "                                 embedding=embeddings,\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a5c5c6-aa8b-4354-b44d-ba3ab061459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b8bfb7-436d-45b0-903a-88c934015d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectordb = Chroma(persist_directory=persist_directory, \n",
    "                  embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283b7919-cdc6-4e2a-9c93-2d99eea4a9af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff5a666-d633-4adc-a933-40d62e675b5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17096cb-ff75-4be7-8653-894ef23ba98a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"list the doctor appointments?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ef6e80-971d-4aeb-9adb-5e01328eb854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a27531-5466-4f75-b284-38ec2db3f3fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectordb.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f21244-d69f-419c-8591-4b1b3fa98e79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new chroma collection\n",
    "import chromadb\n",
    "client = chromadb.PersistentClient(path=persist_directory)\n",
    "collection_name = \"mailContent\"\n",
    "collection = client.get_or_create_collection(name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceec8a4-97a2-47c8-9973-e13928da6e8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset=docs\n",
    "from tqdm.notebook import tqdm\n",
    "#!pip3 install --upgrade --quiet jupyter ipywidgets\n",
    "#!conda install -n base -c conda-forge jupyterlab_widgets\n",
    "#!conda install -n pyenv -c conda-forge ipywidgets\n",
    "\n",
    "# Load the supporting evidence in batches of 1000\n",
    "batch_size = 2\n",
    "for i in tqdm(range(0, len(dataset), batch_size), desc=\"Adding documents\"):\n",
    "    collection.add(\n",
    "        ids=[\n",
    "            str(i) for i in range(i, min(i + batch_size, len(dataset)))\n",
    "        ],  # IDs are just strings\n",
    "        documents=dataset[\"support\"][i : i + batch_size],\n",
    "        metadatas=[\n",
    "            {\"type\": \"support\"} for _ in range(i, min(i + batch_size, len(dataset)))\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a18a98-0899-48ab-91d6-8cfa25e1224f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface import (\n",
    "    HuggingFaceModel    \n",
    ")\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "hub_config = {\n",
    "    'HF_MODEL_ID': 'sentence-transformers/all-MiniLM-L6-v2', # model_id from hf.co/models\n",
    "    'HF_TASK': 'feature-extraction'\n",
    "}\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    env=hub_config,\n",
    "    role=role,\n",
    "    transformers_version=\"4.6\", # transformers version used\n",
    "    pytorch_version=\"1.7\", # pytorch version used\n",
    "    py_version=\"py36\", # python version of the DLC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229faa02-41bd-4a5c-b636-1449a506249d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.t2.large\",\n",
    "    endpoint_name=\"minilm-demo1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce9310a-bcfe-4de7-820e-52db3f91c80c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out = encoder.predict({\"inputs\": [\"check embeddings\", \"check few more embeddings for testing \"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41155a71-1c8f-485b-8fc7-eaea782197ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def embed_docs(docs: List[str]) -> List[List[float]]:\n",
    "    out = encoder.predict({'inputs': docs})\n",
    "    embeddings = np.mean(np.array(out), axis=1)\n",
    "    return embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dfc992-31c9-46c2-933c-eb45bdabb1d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "import json\n",
    "\n",
    "endpoint_name = \"minilm-demo\"                                       # Your endpoint name.\n",
    "content_type = \"application/json\"                                     # The MIME type of the input data in the request body.\n",
    "accept = \"application/json\"   \n",
    "input_data = {\"inputs\": [\"check embeddings\", \"check few more embeddings for testing \"]}\n",
    "    # The desired MIME type of the inference in the response.\n",
    "payload =json.dumps(input_data)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c6ca02-3a13-4544-8343-32b349fcab93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    CustomAttributes=\"\", \n",
    "    ContentType=content_type,\n",
    "    Accept=accept,\n",
    "    Body=payload\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7241d1cf-91e2-4cf0-9406-2f9efb666ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0bb0da-0498-412b-99cf-83fcd5a0b987",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_data = json.loads(response['Body'].read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b65c5fe-35b4-473a-9939-f5a45040c9c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(output_data[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b426af-6c6f-4023-9c89-e74af28a596d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('s3://abb8-ml-model/dailydownload/mailContents.json')\n",
    "print(df[\"mail_body\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672e531-0611-43e3-a041-baac055d76e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df[\"mail_body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2d6801-3caa-4a13-ad4c-9b2ecb530181",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install -U  ipywidgets widgetsnbextension pandas-profiling jupyter tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5498947-e241-4b26-b98d-7ecc5e5885bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(embed_docs( df[\"mail_body\"][0:1].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909e6576-3ee4-4a82-81bf-aab7996e9cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!jupyter nbextension enable --py widgetsnbextension\n",
    "import numpy as np\n",
    "!pip install --upgrade --quiet jupyter_client ipywidgets\n",
    "from ipywidgets import FloatProgress\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Load the supporting evidence in batches of 1000\n",
    "batch_size = 2\n",
    "for i in range(0, len(df), batch_size):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(df))\n",
    "    collection.add(\n",
    "        ids=[\n",
    "            str(i) for i in range(i, min(i + batch_size, len(df)))\n",
    "        ],  # IDs are just strings       \n",
    "        embeddings = embed_docs( df[\"mail_body\"][i:i_end].tolist()),\n",
    "        #documents=df[\"mail_body\"][i : i + batch_size],        \n",
    "        metadatas= [{'text': text} for text in df[\"mail_body\"][i:i_end]],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb84028c-a2fb-4e87-a7b5-f699b88ea9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(\n",
    "    query_texts='when is doctor appointment',\n",
    "    n_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c1f872-2d04-46b5-acc7-b12092418a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4adab1-95b8-4163-aadb-5d0c32d9ec62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66149376-f39b-4992-a357-27b3a127bcc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03743a1-1f72-4cf5-8c0f-f2fe7a2c6710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6f6ab1-b2ef-41cc-b071-65ed1a2c65be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Answer the following QUESTION based on the CONTEXT\n",
    "given. If you do not know the answer and the CONTEXT doesn't\n",
    "contain the answer truthfully say \"I don't know\".\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "ANSWER:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02502dd-28a0-4d1c-b870-b2c33abb914e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "context= df.groupby(['mail_body'])[\"mail_body\"].agg(lambda x: ''.join(x))        \n",
    "question=\"Can you please provide me with a list of my upcoming tasks based on the given context information?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada0a7ad-22d3-49fc-8b28-315c1edbd942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d21ef4-317c-49c5-9bf1-a4d5633a4e95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_input = prompt_template.replace(\"{context}\", context.to_string()).replace(\"{question}\", question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef53a90-f663-479d-9f40-638e12206b31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(text_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188fd21e-3f9a-4c77-9b51-ae1800b6a913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "#%pip install -U sagemaker\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'google/flan-t5-large',\n",
    "\t'HF_TASK':'text-generation'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2a5e3c-3289-4c42-bc11-c0898edfab2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\ttransformers_version='4.26.0',\n",
    "\tpytorch_version='1.13.1',\n",
    "\tpy_version='py39',\n",
    "\tenv=hub,\n",
    "\trole=role, \n",
    ")\n",
    "\n",
    "predictor = huggingface_model.deploy(\n",
    "\tinitial_instance_count=1, # number of instances\n",
    "\tinstance_type='ml.g5.2xlarge' # ec2 instance type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d14c39-359b-4386-8fb8-0d0579be4ea5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out = predictor.predict({\"inputs\": text_input})\n",
    "generated_text = out[0][\"generated_text\"]\n",
    "print(f\"[Output]: {generated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dfee1f-f027-4742-8394-fe147884a3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.0.0 Python 3.10 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-2.0.0-gpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
